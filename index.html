<!doctype html>
<html lang="ja">
<head>
<meta charset="utf-8">
<title>Keita Higuchi's Web page/樋口啓太のwebページ</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="copyright" content="Keita Higuchi">
<meta name="description" content="Keita Higuchi's Web page/樋口啓太のwebページ">
<meta name="keywords" content="Keita Higuchi, 樋口啓太, ひぐちけいた, research, human-computer interaction, computer vision, unmanned aereal vehicle, telepresence">
<link rel="stylesheet" href="css/style.css">
<!--[if lt IE 9]>
<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
<script type="text/javascript" src="js/openclose.js"></script>
</head>

<body id="top">

<header>
<h1>Keita Higuchi, Ph.D. 樋口啓太 博士(学際情報学)</h1>
</header>

<div id="container">

<div id="contents">

<div id="main">

<section>
<h2>About</h2>
Keita Higuchi is Lead Research Scientist at SB Intuitions and a co-founder at Jokun Brewing Lab. He received his B.A. degree in Kanazawa Institute of Technology. He also received his M.S. and Ph.D. degree in the University of Tokyo. He was supervised by Prof. Jun Rekimoto at Rekimoto Lab on Human-UAV interaction projects which won a Emerging Technologies Prize at ACM Siggraph Asia 2012. 
He joined Multimedia, Interaction, and Communication (MIC) group, Microsoft Research Redmond as a research intern student twice on the Viiboard Project that his paper was accepted by CHI 2015. He was working with Prof. Yoichi Sato on the CREST project as a Project Research Associate/Lecturer at Institute of Industrial Science. The project focuses on understanding group attention and activities by analyzing information gathered from multiple wearable devices, such as wearable cameras and eye trackers. 
He was also Researcer at Preferred Networks to lead the HCI for ML projects. He is interested in remote collaboration and video browsing interface studies that the papers were published in CHI 2016, CHI 2017, and IUI 2019 respectively. He is also actively working on accessibility technologies for people with disabilities (e.g. blind, and ASD) that the paper was accepted to IUI 2018, CHI 2019, and CHI 2020. He is now interested HCI for Machine Learning projects where the papers are published in DIS 2021, PACM HCI, and SIGGRAPH Asia 2023.</section>


<section>
<h2>Selected Publications</h2>
<ol>
<li>Wataru Kawabe, Taisuke Hashimoto, Fabrice Matulic, Takeo Igarashi, and <span style="text-decoration:underline;">Keita Higuchi</span>. 2023.  <strong>Interactive Material Annotation on 3D Scanned Models leveraging Color-Material Correlation</strong>, SIGGRAPH ASIA 2024 Technical Communication. https://dl.acm.org/doi/abs/10.1145/3610543.3626170</li>
<li>Kotaro Oomori, Wataru Kawabe, Fabrice Matulic, Takeo Igarashi, and <span style="text-decoration:underline;">Keita Higuchi</span>. 2023. <strong>Interactive 3D Annotation of Objects in Moving Videos from Sparse Multi-view Frames</strong>, Proceedings of the ACM on Human-Computer Interaction, 7 (ISS2023), 309-326. https://dl.acm.org/doi/10.1145/3626476</li>
<li><span style="text-decoration:underline;">Keita Higuchi</span>, Shotaro Sano, and Takeo Igarashi. 2021. Interactive Hyperparameter <strong>Optimization with Paintable Timelines</strong>. In Designing Interactive Systems Conference 2021 (DIS '21). Association for Computing Machinery, New York, NY, USA, 1518–1528. https://doi.org/10.1145/3461778.3462077</li>
<li><span style="text-decoration:underline;">Keita Higuchi</span>, Hiroki Tsuchida, Eshed Ohn-Bar, Yoichi Sato, Kris Kitani, <strong>Learning Context-Dependent Personal Preferences for Adaptive Recommendation</strong>, ACM Transaction on Interactive Intelligent Systems, vol.10, no.3, article 23 (November 2020), 26 pages. DOI:https://doi.org/10.1145/3359755<span style="color:#ff0000;">[Accepted!]</span><a href="http://keihigu.github.io/preprint/HOTSK_Tiis2020Nov_preprint.pdf">[preprint]</a></li>
<li>Rie Kamikubo, Naoya Kato, <span style="text-decoration:underline;">Keita Higuchi</span>, Ryo Yonetani, Yoichi Sato, <strong>Support Strategies for Remote Guides in Assisting People with Visual Impairments for Effective Indoor Navigation</strong>, CHI 2020, April 2020, DOI:https://doi.org/10.1145/3313831.3376823.. <span style="color:#ff0000;">[Accepted!]</span><a href="http://keihigu.github.io/preprint/KKHYS-CHI2020.pdf">[preprint]</a></li>
<li>Seita Kayukawa, <span style="text-decoration:underline;">Keita Higuchi</span>, João Guerreiro, Shigeo Morishima, Yoichi Sato, Kris Kitani, Chieko Asakawa, <strong>BBeep: A Sonic Collision Avoidance System for Blind Travellers and Nearby Pedestrians</strong>, Proceedings of  CHI 2019, May 2019. <span style="color:#ff0000;">[Accepted!]</span><a href="https://wotipati.github.io/projects/BBeep/BBeep.html">[project page]</a></li>
<li>Irshad Abibouraguimane, Kakeru Hagihara,  <span style="text-decoration:underline;">Keita Higuchi</span>, Yuta Itoh, Yoichi Sato, Tetsu Hayashida, and Maki Sugimoto, <strong>CoSummary: Adaptive Fast-Forwarding for Surgical Videos by Detecting Collaborative Scenes Using Hand Regions and Gaze Positions</strong>, Proceedings of IUI 2019, March 2019. <span style="color:#ff0000;">[Accepted!]</span></li>		
<li><span style="text-decoration:underline;">Keita Higuchi</span>, Soichiro Matsuda, Rie Kamikubo, Takuya Enomoto, Yusuke Sugano, Jun'ichi Yamamoto, and Yoichi Sato, <strong>Visualizing Gaze Direction to Support Video Coding of Social Attention for Children with Autism Spectrum Disorder</strong>, Proceedings of IUI 2018. <span style="color:#ff0000;"></span><span style="color:#ff0000;"><a href="http://keihigu.github.io/preprint/HMKEKYS_IUI2018-preprint.pdf">[preprint]</a></li>
<li><span style="text-decoration:underline;">Keita Higuchi</span>, Ryo Yonetani, and Yoichi Sato, <strong>EgoScanning: Quickly Scanning First-Person Videos with Egocentric Elastic Timelines</strong>, Proceedings of CHI 2017. <a href="http://keihigu.github.io/preprint/HYS-CHI2017-preprint.pdf">[preprint]</a><span style="color:#ff0000;"></span></li>
<li><span style="text-decoration:underline;">Keita Higuchi</span>, Ryo Yonetani, and Yoichi Sato, <strong>Can Eye Help You?: Effects of Visualizing Eye Fixations on Remote Collaboration Scenarios for Physical Tasks</strong>, Proceedings of CHI 2016. <span style="color:#ff0000;"><a href="http://keihigu.github.io/preprint/HYS-CHI2016-preprint.pdf">[preprint]</a></span></li>
<li><span style="text-decoration:underline;">Keita Higuchi</span>, Yinpeng Chen, Philip A Chou, Zhengyou Zhang, Zicheng Liu, <strong>ImmerseBoard: Immersive Telepresence Experience using a Digital Whiteboard</strong>, Proceedings of CHI 2015, Seoul, Korea, 2015. <a href="http://research.microsoft.com/pubs/244987/p2383-higuchi-published.pdf">[pdf]</a></li>
<li>Kei Nitta, <span style="text-decoration:underline;">Keita Higuchi</span>, Yuichi Tadokoro, Jun Rekimoto, <strong>Shepherd Pass: Ability Tuning for Augmented Sports using Ball-Shaped Quadcopter</strong>, Proceedings of ACE 2015, Iskandar, Malaysia, 2015. <a href="http://keihigu.github.io/preprint/NHTR-ACE2015-preprint.pdf">[preprint]</a></li>
<li><span style="text-decoration:underline;">Keita Higuchi</span>, Katsuya Fujii, Jun Rekimoto <strong>Flying Head: A Head-Synchronization Mechanism for Flying Telepresence</strong>，The 23rd h IEEE International Conference on Artificial Reality and Telexistence (ICAT 2013)，December 11-13, 2013, Tokyo, Japan.<a href="http://keihigu.github.io/preprint/HFR-ICAT2013-preprint.pdf">[preprint]</a></li>
</ol>
</section>

<section>
<h2>Research Interests</h2>
Human-Computer Interaction, HCI for Machine Learning, Craftbeer Brewing, Computer Vision, Human-UAV Interaction, Accessibility, Telepresence, Augmented Human.
</section>
</div>
<!--/main-->

<div id="sub">

<div id="head">

<p id="logo"><a href="index.html"><img src="images/keita.jpg" width="200" height="135" alt="Keita Higuchi"></a></p>
<section>
Keita Higuchi, Ph.D.</br>
HCI Researcher</br>
Craft Beer Brewer</br>
<a href="https://scholar.google.co.jp/citations?user=gpKUIrQAAAAJ">Google Scholar</a></a>
</section>
<nav id="menubar">
<ul>
<li><a href="index.html">HOME</a></li>
<li><a href="profile.html">Profile</a></li> 
<li><a href="publications.html">Publications</a></li>
<li><a href="projects.html">Projects</a></li>
<!-- <li><a href="code.html">Code and Dataset</a></li> -->
<li><a href="KeitaHiguchi_CV.pdf">Resume/CV (PDF)</a></li>
</ul>
</nav>

</div>
<!--/head-->

<section>
<h2>Contact</h2>
<p>khiguchi ( a t ) acm.org</p>
</section>

</div>
<!--/sub-->

<p id="pagetop"><a href="#">↑ PAGE TOP</a></p>

</div>
<!--/contents-->

</div>
<!--/container-->

<footer>
<small>Copyright&copy; 2015 <a href="index.html">Keita Higuchi</a>　All Rights Reserved.</small>
<span class="pr"><a href="http://template-party.com/" target="_blank">Web Design:Template-Party</a></span>
</footer>

<!--スライドショースクリプト-->
<script type="text/javascript" src="js/slide_simple_pack.js"></script>

<!--スマホ用更新情報-->
<script type="text/javascript">
if (OCwindowWidth() < 480) {
	open_close("newinfo_hdr", "newinfo");
}
</script>

</body>
</html>
